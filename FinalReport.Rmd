---
title: "What is the Value of a University's Pedigree?"
author: "Angela, Jeremy, George, Matt"
date: "May 3, 2018"
output: 
  word_document:
     toc: true
     toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Load Package and Datasets, message=FALSE}
library(perturb)
library(tidyverse)
library(tree)
library(class)
library(car)
library(lmtest)
library(car)
library(corrplot)
fullDataTraining <- read.csv("FullDataTrainingComplete.csv", header = TRUE, stringsAsFactors = FALSE)
```

##Section 1 The Analytics Question:

One of the main reasons students attend universities in the US is the hope of getting a better paying job once they have graduated. Our hope is to determine whether certain universities provide a better opportunity of achieving this. Our team wants to predict, given a school and corresponding school statistics, can we predict the starting median salary that a graduate from that particular university would earn in their first year out of school.

Since our team wants to predict the starting salary of new graduates, this problem is a quantitative one. Our main analytic goals for these models are inference and interpreation, examining and attempting to explain the relationships between the starting median salary and the other available statistics for each school, as well as attempting to better understand the final results.  Since we are presenting this information to potential college students and their families through their high schools, we feel it is important to be able to explain our findings in an easy to approach manner that will help inform their future college decisions.

##Section 2 The Business Rational:

As consultants hired by a high school, it is imperative that we deliver findings that are easy to understand to better inform schools, as well as students, about the real-world effect on how their college choice will alter their potential starting salary.

For students entering college, a career is several years away. Knowing what the average salary is for alumni may influence their decision as to what school they choose. In addition, with the known cost of the university and their predicted salaries upon graduation, they would be able to determine a general return on investment, as well how long their payback period would be.  Furthermore, should the student be deciding between two or more schools of similar standing but a large difference in tuition cost, such a prediction would allow them to know if such an increase in cost would be worth it.

As admission rates throughout the country are decreasing, schools are competing to attract the top students more then ever. While there are numerous reasons for students to choose specific schools, such as proximity to home, the prestige of the university, or the school having the best preferred program, one of the major reasons to attend is the perception of higher salaries. Going to a university is an investment and the cost of that investment is increasing. Therefore universities need to justify that investment to their customers, one of the best ways to do this is with the average starting salary of new alumnus.

##Section 3 Description of the Data: 

The data for this project originated from two sources. The first is from a Kaggle Dataset called Where it Pays to Attend College. This data set includes the university, region, and the schools alumnus median starting salary in dollars. The second was collected from publicly available information on www.collegedata.com, this data includes admission rates of the schools (as a decimal), the number of undergraduates, cost of tuition in dollars, and the location of the school. These datasets were combined together and is attached to this report.

Below, we have generated a correlation matrix using the quantitative variables from our dataset.  This is to help us understand some possible correlations that exist in the data from the beginning, before we begin transforming the data.  One large positive correlation that already exists is the one between the in-state tuition and the out-of-state tuition.  This makes sense as, if the university is a private one, then the cost would be the same whether the student lived in the state or not.  However, another correlation that caught our attention was the negative correlation  between the starting median salary and the admit rate of the university.  Upon further investigation, this made sense as schools that were harder to be accepted in would result in the university graduates having a higher starting salary.  With these correlations in mind for our predictive modeling, we proceeded with the data pre-processing.

```{r}
attach(fullDataTraining)
fdtData <- as.matrix(data.frame(Starting.Median.Salary,AdmitRate,CostIState, CostOState, Undergraduates, Applicants))
correlation <- cor(fdtData, use="complete.obs")
corrplot(correlation, method="pie")
       detach(fullDataTraining)
```

##Section 4 Pre-Processing:

The data set was pulled from two different sources which required us to combine in to one data set in order to allow us to analyze the data.  The two data sets combined provided a complete picture of an undergraduate student's salary post-graduation from almost any American University.  A challenge in our data is that out of the 1800 universities that we gathered information on, only 311 of the universities had data in each column that we needed in order to properly analyze the data set.  We decided to utilize only the 311 complete rows to conduct our analysis. 

Once determined which variables we were going to use, we ran a unlogged ggplot and histogram to identify if the data was normally distributed but idenitified that the data was skewed to the right.  We then ran a logged ggplot and histogram to correct for the right skeweness; however, this did not correct for the skeweness.  Utilizing a boxplot, we were able to determine that several data points were significantly outside the normal distribution of the rest of the data and this is what is causing the significant right skewness in the data.  After some discussion, we determined that by identifying and removing these data points that the rest of the data would be normalized enough to utilize for the project. 

We were able to determine that 17 universities (which consisted of 5 Ivy League Universities and Top Technical schools) were the outliers of the data set.  To note, these 17 universities starting salaries were significantly higher than the bulk of the universities but this is expected with these 17 universities due to the prestige associated with attending these specific universities. 

Once the outliers were removed, we conducted another logged and unlogged qqplots and histograms.  As expected, the qqplots and histograms showed the data was more normally distributed.  We determined that logging the data had no significant effect resulting in our choice to use unlogged data for this analysis.

```{r}
qqnorm(fullDataTraining$Starting.Median.Salary, main = "Starting Median Salary Q-Q Plot")
qqline(fullDataTraining$Starting.Median.Salary)

hist(fullDataTraining$Starting.Median.Salary, main = "Histogram of Starting Median Salary", xlab = "Starting Median Salary")

qqnorm(log(fullDataTraining$Starting.Median.Salary), main = "log(Starting Median Salary) Q-Q Plot")
qqline(log(fullDataTraining$Starting.Median.Salary))

hist(log(fullDataTraining$Starting.Median.Salary), main = "Histogram of log(Starting Median Salary)", xlab = "log(Starting Median Salary)")

boxplot(fullDataTraining$Starting.Median.Salary, main = "Boxplot of Starting Median Salary")

calc.limits <- function(x, na.rm = TRUE) {
    qnt <- quantile(x, probs=c(.25, .75), na.rm = na.rm)
    H <- 1.5 * IQR(x, na.rm = na.rm)
    lwr <- qnt[1] - H
    upr <- qnt[2] + H
    c(lwr, upr)
}
calc.limits(fullDataTraining$Starting.Median.Salary)
fDTNoOut<- fullDataTraining%>% 
  filter(Starting.Median.Salary>32475 & Starting.Median.Salary<58275)

#University Outliers are as follows:
setdiff(fullDataTraining,fDTNoOut) %>% arrange(desc(Starting.Median.Salary)) %>% select(University, Starting.Median.Salary)

qqnorm(fDTNoOut$Starting.Median.Salary, main = "Starting Median Salary (Without Outliers) Q-Q Plot")
qqline(fDTNoOut$Starting.Median.Salary)

hist(fDTNoOut$Starting.Median.Salary, main = "Histogram of Starting Median Salary", xlab = "Starting Median Salary")

qqnorm(log(fDTNoOut$Starting.Median.Salary), main = "log(Starting Median Salary) (Without Outliers) Q-Q Plot")
qqline(log(fDTNoOut$Starting.Median.Salary))

hist(log(fDTNoOut$Starting.Median.Salary), main = "Histogram of log(Starting Median Salary) (Without Outliers)", xlab = "log(Starting Median Salary)")
```

##Section 5 Model Justification: 

 

As shown below, our dataset conforms with these OLS assumptions: errors are normally distributed, X's are independent,	Y and X's have linear reltionship, observations are independent, errors are independent, the error average is 0, and error variance is constant. The assumptions which our dataset departs from OLS is Y is continuous. We find that because the errors are normally distributed and Y is now normally distributed it is still ok to run OLS even though Y is not continuous.

If university can lead to a better paying job down the road does the university matter. The goal of the project is to show how a choice in a school can lead to this difference. Therefore our goal is inference and interpretablity of the result.This allows for the results to be useful for both students and student's families and schools. 

The outcome variable our project is trying to explain is the Starting Median Salary. The predictors used were Cost of Out of State Tuition, the Number of Undergraduates, Private/Public School, Percieved Entrance Difficulty, Admission Rate, the Number of Applicants and the Region.

The models used were OLS, WLS, and Piecewise because of their ability to be used for interpretability and inference. The first specification used was No Transformation which incorporated the all the variables listed above without transformations, to establish a baseline of the models. The next specification was The Log transformed outcome variable, but all predictors remained the same. This was used because y showed signs of not being continuous. Lastly an interaction effect between number of undergraduates and college type because public schools typically have a higher population of students then privates schools so this difference was thought to be caught with an interaction variable between the two.

```{r training split section 4}
set.seed(123)
train <- sample(1:nrow(fDTNoOut), 0.8*nrow(fDTNoOut))
```

```{r OLS Test - Y is Continuous section 4}
#Y cannot be less then 0, as tuition, salary, and acceptance rate cannot be below 0, therefore Y is not continuous.
```

```{r OLS Test - Errors are Normally Distributed section 4, warning=FALSE}

plot(lm(Starting.Median.Salary~.,data=fDTNoOut), which = 2)

```

```{r OLS Assumptions - Xs are Independent section 4}

ols.full <- lm(Starting.Median.Salary ~ CostIState + CostOState + Undergraduates + AdmitRate + Applicants, data=fDTNoOut)

collin.diag = colldiag(mod=ols.full, scale=TRUE, center=TRUE, add.intercept=TRUE)

collin.diag

```

```{r OLS VIF}
ols.full <- lm(Starting.Median.Salary ~ CostOState + Undergraduates + CollegeType +
EntranceDifficulty + AdmitRate + Applicants + Region, data=fDTNoOut)

vif(ols.full)
```

```{r OLS Assumptions - Error Variance is Constant section 4}
lm.formula=Starting.Median.Salary~.
bptest(lm.formula, data=fDTNoOut)
```

BP-Test resulted in p-value = 0.3638, so unlikely Heteroscedasticity is present.

```{r OLS Assumptions - Observations/Errors are Independent section 4}

dwtest(ols.full)

```

```{r OLS Assumptions section 4}
#OLS assumptions:
 #YC (Y is continuous): No
 #EN (Errors are normally distributed): Yes
 #XI (X's are independent): Yes
 #LI (Y and X's have linear reltionship): Yes
 #OI (Observations are independent): Yes
 #EI (Errors are independent): Yes
 #EA (The error average is 0): Yes
 #EV (The error variance is constant (homoscedasticity)): Yes
```

```{r OLS No Transformation}
ols.noTransformation <- lm(Starting.Median.Salary ~ CostOState + Undergraduates + CollegeType + EntranceDifficulty + AdmitRate + Applicants + Region, data=fDTNoOut[train,])
ols.noTransformation.mse.test <- mean((fDTNoOut$Starting.Median.Salary-predict(ols.noTransformation,fDTNoOut))[-train]^2) 
```

```{r OLS Logged}
ols.logged <- lm(log(Starting.Median.Salary) ~ CostOState + Undergraduates + CollegeType +EntranceDifficulty + AdmitRate + Applicants + Region, data=fDTNoOut[train,])
ols.logged.mse.test <- mean((fDTNoOut$Starting.Median.Salary-exp(predict(ols.logged,fDTNoOut)))[-train]^2) 
```

```{r OLS Interaction}
ols.interaction <- lm(Starting.Median.Salary ~ CostOState + EntranceDifficulty + 
                 CollegeType*Undergraduates + Applicants + AdmitRate + Region, data=fDTNoOut[train,])
ols.interaction.mse.test <-
mean((fDTNoOut$Starting.Median.Salary-predict(ols.interaction,fDTNoOut))[-train]^2) 
```

```{r WLS No Transformation}
wls.noTransformation <- lm(Starting.Median.Salary ~ CostOState + Undergraduates + CollegeType +
EntranceDifficulty + AdmitRate + Applicants + Region, data=fDTNoOut[train,])

lm.formula <- Starting.Median.Salary ~ CostOState + Undergraduates + CollegeType +
EntranceDifficulty + AdmitRate + Applicants + Region

lm.fit.wls1=lm(lm.formula,data=fDTNoOut[train,], weights=1/wls.noTransformation$residuals^2)

wls.noTransformation.mse.test <- mean((fDTNoOut$Starting.Median.Salary-predict(lm.fit.wls1,fDTNoOut))[-train]^2)
```

```{r WLS Logged}
wls.logged <- lm(log(Starting.Median.Salary) ~ CostOState + Undergraduates + CollegeType +
EntranceDifficulty + AdmitRate + Applicants + Region, data=fDTNoOut[train,])

lm.formula <- log(Starting.Median.Salary) ~ CostOState + Undergraduates + CollegeType +
EntranceDifficulty + AdmitRate + Applicants + Region

lm.fit.wls2=lm(lm.formula,data=fDTNoOut[train,], weights=1/wls.logged$residuals^2)

wls.logged.mse.test <- mean((fDTNoOut$Starting.Median.Salary-exp(predict(lm.fit.wls2,fDTNoOut)))[-train]^2)
```

```{r WLS Interaction}
wls.interaction <- lm(Starting.Median.Salary ~ CostOState + EntranceDifficulty + 
                 CollegeType*Undergraduates + Applicants + AdmitRate + Region, data=fDTNoOut[train,])

lm.formula <- Starting.Median.Salary ~ CostOState + EntranceDifficulty + 
                 CollegeType*Undergraduates + Applicants + AdmitRate + Region
lm.fit.wls3=lm(lm.formula,data=fDTNoOut[train,], weights=1/wls.interaction$residuals^2)
wls.interaction.mse.test <- mean((fDTNoOut$Starting.Median.Salary-predict(lm.fit.wls3,fDTNoOut))[-train]^2)
```

```{r Piecewise Setup}
admitlimits=range(fDTNoOut$AdmitRate)
admit.seq=seq(from=admitlimits[1],to=admitlimits[2])
plot(fDTNoOut$AdmitRate,fDTNoOut$Starting.Median.Salary,xlim=admitlimits,cex=.5,col="black", xlab = "Admit Rate", ylab = "Starting Median Salary", main = "Admit Rate vs. Starting Median Salary")
# Knots look to be at AdmitRate .155 and AdmitRate .6
abline(v=c(.155,.6), col="red", lty=2, lwd=1)
```

```{r Piecewise AdmitRate, echo=FALSE, eval=FALSE}
fit.piecewise=lm(Starting.Median.Salary~AdmitRate+I((AdmitRate-.155)*(AdmitRate>.155))+I((AdmitRate-.6)*(AdmitRate>.6)), data=fDTNoOut)
summary(fit.piecewise)
```

```{r Piecewise No Transformation}
piecewise.noTransformation=lm(Starting.Median.Salary~ CostOState + EntranceDifficulty + 
                 CollegeType+Undergraduates + Applicants + Region+
                   AdmitRate+I((AdmitRate-.155)*(AdmitRate>.155))+I((AdmitRate-.6)*(AdmitRate>.6)), data=fDTNoOut[train,])
pw.noTransformation.mse.test <- mean((fDTNoOut$Starting.Median.Salary-predict(piecewise.noTransformation,fDTNoOut))[-train]^2)
```

```{r Piecewise Logged}
piecewise.logged=lm(log(Starting.Median.Salary)~ CostOState + EntranceDifficulty + 
                 CollegeType+Undergraduates + Applicants + Region+
                   AdmitRate+I((AdmitRate-.155)*(AdmitRate>.155))+I((AdmitRate-.6)*(AdmitRate>.6)), data=fDTNoOut[train,])
pw.logged.mse.test <- mean((fDTNoOut$Starting.Median.Salary-exp(predict(piecewise.logged,fDTNoOut)))[-train]^2)
```

```{r Piecewise Interaction}
piecewise.interaction=lm(Starting.Median.Salary~ CostOState + EntranceDifficulty + 
                 CollegeType*Undergraduates + Applicants + Region+
                   AdmitRate+I((AdmitRate-.155)*(AdmitRate>.155))+I((AdmitRate-.6)*(AdmitRate>.6)), data=fDTNoOut[train,])
pw.interaction.mse.test <- mean((fDTNoOut$Starting.Median.Salary-predict(piecewise.interaction,fDTNoOut))[-train]^2)
```

```{r MSE}
mse.table<- matrix(c(ols.noTransformation.mse.test, ols.logged.mse.test, ols.interaction.mse.test,
                     wls.noTransformation.mse.test, wls.logged.mse.test, wls.interaction.mse.test, 
                     pw.noTransformation.mse.test, pw.logged.mse.test, pw.interaction.mse.test),
                   ncol=3, byrow=TRUE)
colnames(mse.table) <- c("No Transformations","Logged", "Interaction")
rownames(mse.table) <- c("OLS","WLS","Piecewise")
mse.table <- as.table(mse.table)
mse.table
```

```{r Prediction}
summary(lm.fit.wls1)
```

##Section 6 Analysis of Results:

The best model was a plain Weighted Least Squares Regression where the outcome variable was not logged and there was no interaction effect. We chose this not only because it has the lowest test MSE, but also because it weighted certain variables to correct for errors that would have been seen in the ols model. This variable Undergraduates was seen as not significant in the model, but we though it was relevant because of it is possible that it is also a proxy for class sizes which could effect the quality of a graduates education i.e. larger schools potentially have larger class sizes.

##Section 7 Conclusion:

A short section with final thoughts, conclusions and lessons learned. These conclusions must contain a discussion of: 

a.	Your final model method and specification selection. Why did you pick this particular modeling method and model specification.
We select the WLS with no transformations as our model because it has the lowest MSE comparitively to all the other modeling methods and specification combinations while still maintaining our key goal of interpretibility.

b.	The main conclusions of your analysis. These conclusions must answer/solve your analytics question/problem stated in 1 above. Please be brief but concise and discuss the main insights you obtained from your analysis 
We learned that many varibales contribute in determining what the median starting salary is for college graduates. However, our most iluminating find was how much the reputation and branding of a school has on starting median salaries. Our outliers contained 5/7 Ivys and other prestigious schools like MIT and Staford. It appears that these highly prestegious and recognizable schools impact salaries more than the other variables included in our list. It would be interesting to find data and include a school's reputation if we continued on with this project.

c.	A brief statement of your lessons learned in this project in terms of: data issues, methodological challenges, do's and don'ts, what you learned from this experience. You don't need to address all of this. But please be thoughtful and make it interesting. 
Since we have an ad hoc dataset (we created it), we ran into issues of having a small number of data points with full data. We only have information for roughly 17% of the schools we collected. 
Understnading how to re-transform logged models to get an MSE than can be compared to our other two models was challenging.

