---
title: "What is the Value of a University's Pedigree?"
author: "Angela, Jeremy, George, Matt"
date: "May 3, 2018"
output: 
  word_document:
     toc: true
     toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r Load Package and Datasets, message=FALSE}
library(perturb)
library(tidyverse)
library(tree)
library(class)
library(car)
library(FNN)
library(lmtest)
library(randomForest)
library(car)
library(corrplot)
fullDataTraining <- read.csv("FullDataTrainingComplete.csv", header = TRUE, stringsAsFactors = FALSE)

```


The final project report will contain the following sections:

##Section 1 Analytics Question/Problem (5 pts.) 

One of the main reasons students attend universities in the US is the hope of getting a better paying job once they have graduated. Our hope is to determine whether certain universities provide a better opportunity of achieving this. Our team wants to predict the starting median salary that a graduate from a particular university would earn in their first year out of school, given a school's admittence rate.

Since our team wants to predict the starting salary of new graduates, this problem is a quantitative one. Our main analytic goals for these models are inference and interpreation, examining and attempting to explain the relationships between the starting median salary and the other available statistics for each school, as well as attempting to better understand the final results.  Since we are presenting this information to potential college students and their families through their high schools, we feel it is important to be able to explain our findings in an easy to approach manner that will help inform their future college decisions, which is why interpretability is our primary focus.


##Section 2 Business Rational (10 pts.)

As consultants hired by a high school, it is imperative that we deliver findings that are easy to understand to better inform schools, as well as students, about the real-world effect on how their college choice will alter their potential starting salary.

For students entering college, a career is several years away. Knowing what the average salary is for alumni immediately following graduation may influence their decision as to what school they choose. In addition, with the known cost of the university and their predicted salaries upon graduation, they would be able to determine a general return on investment, as well how long their payback period would be.  Furthermore, should the student be deciding between two or more schools of similar standing but a large difference in tuition cost, such a prediction would allow them to know if such an increase in cost would be worth it.

As admission rates throughout the country are decreasing, schools are competing to attract the top students more then ever. While there are numerous reasons for students to choose specific schools, such as proximity to home, the prestige of the university, or the school having the best preferred program, one of the major reasons to attend is the perception of higher salaries. Going to a university is an investment and the cost of that investment is increasing. Therefore universities need to justify that investment to their customers, one of the best ways to do this is with the average starting salary of new alumnus.


##Section 3 Description of the Data (10 pts.) 

The data for this project originated from two sources. The first is from a Kaggle Dataset called "Where it Pays to Attend College". This data set includes the university name, region, and the schools alumnus median starting salary in dollars. The second was collected from publicly available information on www.collegedata.com, this data includes admission rates of the schools (as a decimal), the number of undergraduates, cost of tuition in dollars, and the location of the school (city/state). These datasets were combined together and is attached to this report.

Below, we have generated a correlation matrix using the quantitative variables from our dataset.  This is to help us understand some possible correlations that exist in the data from the beginning, before we begin transforming the data.  

```{r}
attach(fullDataTraining)
fdtData <- as.matrix(data.frame(Starting.Median.Salary,AdmitRate,CostIState, CostOState, Undergraduates, Applicants))
correlation <- cor(fdtData, use="complete.obs")
corrplot(correlation, method="circle")
detach(fullDataTraining)
```
One large positive correlation that already exists is the one between the in-state tuition and the out-of-state tuition.  This makes sense as if the university is a private one, then the cost would be the same whether the student lived in the state or not.  However, another correlation that caught our attention was the negative correlation  between the starting median salary and the admit rate of the university.  Upon further investigation, this made sense as schools that were more selective resulted in the university's graduates having a higher starting salary.  With these correlations in mind for our predictive modeling, we proceeded with the data pre-processing.


##Section 4 Pre-Processing	 (10 pts.) 

A. A discussion of any pre-processing (e.g., grouping, combining variables, etc.) and transformations done with the data (e.g., normality, logs, standardization, non-linear, etc.), along with the rationale for the appropriateness of this transformation.

As we mentioned earlied, our dataset is a combination of information from a kaggle.com dataset and scaping the collegedata.com website. All of this data yielded us 1800 unique universities, however, only 311 of the schools had complete data reported on all the categories, including post undergraduate starting salaries. We used this set of 311 schools as our working dataset. 

To further refine our data set, we utilized a Q-Q Plot to visually see how the data was distributed. The plot identified that the data has some non-normality in it with the starting median salary being skewed right meaning that there may be more extreme values in our data that we did not expect. To correct this, we logged the response variable in order to see if this would normalize the data; however, it did not. The logged Q-Q Plot continued to show a more than non-normal distribution to the data. We then utilized a histogram to further explore how the data was distributed and confirmed that the data was significantly skewed to the right. We then utilized a boxplot in order to identify if there were any data points that “fell” out of the normal distribution and identified that several data points did. This led us to do a function that would identify which data points were significantly different than the rest. There were 17 universities reported starting median salary that is significantly higher than the other universities. This group of schools were identified as “Ivy League” or a technical school that had a reputation of “high caliber” production of students. Since these schools were significantly higher than 75% of the entire data set, we removed these points in order to obtain a more normally distributed data set so that we may further analyze the data. After removing these points, we ran another a normal and a logged Q-Q Plot. Both plots showed a more normal distribution of data but neither plot was more significant than the other.  This is also evident in the histogram that we ran to confirm the data was more normally distributed. We chose to use the non-logged data set to continue with the analysis.

```{r}
qqnorm(fullDataTraining$Starting.Median.Salary, main = "Starting Median Salary Q-Q Plot")
qqline(fullDataTraining$Starting.Median.Salary)

hist(fullDataTraining$Starting.Median.Salary, main = "Histogram of Starting Median Salary", xlab = "Starting Median Salary")

qqnorm(log(fullDataTraining$Starting.Median.Salary), main = "log(Starting Median Salary) Q-Q Plot")
qqline(log(fullDataTraining$Starting.Median.Salary))

hist(log(fullDataTraining$Starting.Median.Salary), main = "Histogram of log(Starting Median Salary)", xlab = "log(Starting Median Salary)")

boxplot(fullDataTraining$Starting.Median.Salary, main = "Boxplot of Starting Median Salary")

calc.limits <- function(x, na.rm = TRUE) {
    qnt <- quantile(x, probs=c(.25, .75), na.rm = na.rm)
    H <- 1.5 * IQR(x, na.rm = na.rm)
    lwr <- qnt[1] - H
    upr <- qnt[2] + H
    c(lwr, upr)
}
calc.limits(fullDataTraining$Starting.Median.Salary)
fDTNoOut<- fullDataTraining%>% 
  filter(Starting.Median.Salary>32475 & Starting.Median.Salary<58275)

#University Outliers are as follows:
setdiff(fullDataTraining,fDTNoOut) %>% arrange(desc(Starting.Median.Salary)) %>% select(University, Starting.Median.Salary)

qqnorm(fDTNoOut$Starting.Median.Salary, main = "Starting Median Salary (Without Outliers) Q-Q Plot")
qqline(fDTNoOut$Starting.Median.Salary)

hist(fDTNoOut$Starting.Median.Salary, main = "Histogram of Starting Median Salary", xlab = "Starting Median Salary")

qqnorm(log(fDTNoOut$Starting.Median.Salary), main = "log(Starting Median Salary) (Without Outliers) Q-Q Plot")
qqline(log(fDTNoOut$Starting.Median.Salary))

hist(log(fDTNoOut$Starting.Median.Salary), main = "Histogram of log(Starting Median Salary) (Without Outliers)", xlab = "log(Starting Median Salary)")

ols.full <- lm(Starting.Median.Salary ~ CostIState + CostOState + Undergraduates + AdmitRate + Applicants, data=fDTNoOut)

collin.diag = colldiag(mod=ols.full, scale=TRUE, center=TRUE, add.intercept=TRUE)

collin.diag

ols.full <- lm(Starting.Median.Salary ~ CostOState + Undergraduates + CollegeType +
EntranceDifficulty + AdmitRate + Applicants + Region, data=fDTNoOut)

vif(ols.full)

```

```{r training split}
set.seed(123)
train <- sample(1:nrow(fDTNoOut), 0.8*nrow(fDTNoOut))
```

```{r OLS Test - Y is Continuous}
#Y cannot be less then 0, as salary cannot be below 0, therefore Y is not continuous over an open interval
```

```{r OLS Test - Errors are Normally Distributed}
fdt=lm(Starting.Median.Salary~., data=fullDataTraining)
plot(fdt)
```

```{r OLS Assumptions - Xs are Independent}
ct1 <- with(fdt.full, c(NA,cons[-length(cons)]))
fdt=lm(Starting.Median.Salary~., data=fullDataTraining)
cd<- colldiag(mod=fdt, scale=FALSE, center=FALSE, add.intercept=TRUE)

```

```{r OLS Assumptions - Error Variance is Constant}
lm.formula=Starting.Median.Salary~.
bptest(lm.formula, data=fullDataTraining)
```

BP-Test resulted in p-value = 0.3638, so unlikely Heteroscedasticity is present.

```{r OLS Assumptions - Observations/Errors are Independent}
dwtest(fdt.full) 
```

```{r OLS Assumptions}
#OLS assumptions:
 #YC (Y is continuous): No
 #EN (Errors are normally distributed): Yes
 #XI (X's are independent): Yes
 #LI (Y and X's have linear reltionship): Yes
 #OI (Observations are independent): Yes
 #EI (Errors are independent): Yes
 #EA (The error average is 0): Yes
 #EV (The error variance is constant (homoscedasticity)): Yes
```


##Section 5 Model Justification (20 pts.) 

A justification for the analytics methods and model specifications used. All methods used must be appropriate and relevant to the problem and you need to provide a justification for the selected methods based on: 

a.	Conformance with or departure from OLS assumptions; If you are using OLS as one of your methods, you must test key OLS assumptions. If you don’t plan to use the OLS model, you need to specify which OLS assumption would be violated. 

As shown in the prior section, our dataset conforms with these OLS assumptions: errors are normally distributed, X's are independent,	Y and X's have linear reltionship, observations are independent, errors are independent, the error average is 0, and error variance is constant. The assumptions which our dataset departs from OLS is Y is continuous as in the context of our problem you cannot have a negative salary. This isn't a huge concern as it is continuous on the interval (0, infinity). Additionally, the errors are normally distributed and Y is now normally distributed so it is ok to run OLS even though Y is not continuous.

b.	Analysis goals (i.e., inference, interpretation and/or accuracy); you must specify your analysis goal(s). 

If university can lead to a better paying job down the road does the university matter. The goal of the project is to show how a choice in a school can lead to this difference. Therefore our goal is inference and interpretablity of the result. This allows for the results to be useful for both students and student's families and schools. 

c.	Predictive accuracy based on cross-validation test statistics. Similarly, the particular model specifications utilized must have a rationale. For example, if you chose a quadratic regression specification, you must have some rationale for the respective non-linear relationship. All projects must be analyzed with a variety of appropriate model with different model specification. Please consult with me if in doubt, but these are the minimum requirements 

The outcome variable our project is trying to explain is the Starting Median Salary. The predictors used were Cost of Out of State Tuition, the Number of Undergraduates, Private/Public School, Percieved Entrance Difficulty, Admission Rate, the Number of Applicants and the Region.

The models used were OLS, WLS, and Piecewise because of their ability to be used for interpretability and inference. The first specification used was No Transformation which incorporated the all the variables listed above without transformations, to establish a baseline of the models. The next specification was The Log transformed outcome variable, but all predictors remained the same. This was used because y showed signs of not being continuous. Lastly an interaction effect between number of undergraduates and college type because public schools typically have a higher population of students then privates schools so this difference was thought to be caught with an interaction variable between the two.

The best model was a plain Weighted Least Squares Regression where the outcome variable was not logged and there was no interaction effect. We chose this not only because it has the lowest test MSE, but also because it weighted certain variables to correct for errors that would have been seen in the ols model. This variable Undergraduates was seen as not significant in the model, but we though it was relevant because of it is possible that it is also a proxy for class sizes which could effect the quality of a graduates education i.e. larger schools potentially have larger class sizes.


<!-- Check Figure Size and If All Packages are Needed -->

All projects must evaluate 3 different methods, with 2 different model specifications for each. You need to provide in this section a sound justification for your choice of models to evaluate. 

<!-- Used echo = FALSE and eval = FALSE to prevent the code chunks for the piecewise AdmitRate from being ran --> 

```{r OLS No Transformation}
ols.noTransformation <- lm(Starting.Median.Salary ~ CostOState + Undergraduates + CollegeType + EntranceDifficulty + AdmitRate + Applicants + Region, data=fDTNoOut[train,])
ols.noTransformation.mse.test <- mean((fDTNoOut$Starting.Median.Salary-predict(ols.noTransformation,fDTNoOut))[-train]^2) 
```

```{r OLS Logged}
ols.logged <- lm(log(Starting.Median.Salary) ~ CostOState + Undergraduates + CollegeType +EntranceDifficulty + AdmitRate + Applicants + Region, data=fDTNoOut[train,])
ols.logged.mse.test <- mean((fDTNoOut$Starting.Median.Salary-exp(predict(ols.logged,fDTNoOut)))[-train]^2) 
```

```{r OLS Interaction}
ols.interaction <- lm(Starting.Median.Salary ~ CostOState + EntranceDifficulty + 
                 CollegeType*Undergraduates + Applicants + AdmitRate + Region, data=fDTNoOut[train,])
ols.interaction.mse.test <-
mean((fDTNoOut$Starting.Median.Salary-predict(ols.interaction,fDTNoOut))[-train]^2) 
```

```{r WLS No Transformation}
wls.noTransformation <- lm(Starting.Median.Salary ~ CostOState + Undergraduates + CollegeType +
EntranceDifficulty + AdmitRate + Applicants + Region, data=fDTNoOut[train,])

lm.formula <- Starting.Median.Salary ~ CostOState + Undergraduates + CollegeType +
EntranceDifficulty + AdmitRate + Applicants + Region

lm.fit.wls1=lm(lm.formula,data=fDTNoOut[train,], weights=1/wls.noTransformation$residuals^2)

wls.noTransformation.mse.test <- mean((fDTNoOut$Starting.Median.Salary-predict(lm.fit.wls1,fDTNoOut))[-train]^2)
```

```{r WLS Logged}
wls.logged <- lm(log(Starting.Median.Salary) ~ CostOState + Undergraduates + CollegeType +
EntranceDifficulty + AdmitRate + Applicants + Region, data=fDTNoOut[train,])

lm.formula <- log(Starting.Median.Salary) ~ CostOState + Undergraduates + CollegeType +
EntranceDifficulty + AdmitRate + Applicants + Region

lm.fit.wls2=lm(lm.formula,data=fDTNoOut[train,], weights=1/wls.logged$residuals^2)

wls.logged.mse.test <- mean((fDTNoOut$Starting.Median.Salary-exp(predict(lm.fit.wls2,fDTNoOut)))[-train]^2)
```

```{r WLS Interaction}
wls.interaction <- lm(Starting.Median.Salary ~ CostOState + EntranceDifficulty + 
                 CollegeType*Undergraduates + Applicants + AdmitRate + Region, data=fDTNoOut[train,])

lm.formula <- Starting.Median.Salary ~ CostOState + EntranceDifficulty + 
                 CollegeType*Undergraduates + Applicants + AdmitRate + Region
lm.fit.wls3=lm(lm.formula,data=fDTNoOut[train,], weights=1/wls.interaction$residuals^2)
wls.interaction.mse.test <- mean((fDTNoOut$Starting.Median.Salary-predict(lm.fit.wls3,fDTNoOut))[-train]^2)
```

```{r Piecewise Setup}
admitlimits=range(fDTNoOut$AdmitRate)
admit.seq=seq(from=admitlimits[1],to=admitlimits[2])
plot(fDTNoOut$AdmitRate,fDTNoOut$Starting.Median.Salary,xlim=admitlimits,cex=.5,col="black", xlab = "Admit Rate", ylab = "Starting Median Salary", main = "Admit Rate vs. Starting Median Salary")
# Knots look to be at AdmitRate .155 and AdmitRate .6
abline(v=c(.155,.6), col="red", lty=2, lwd=1)
```

```{r Piecewise AdmitRate, echo=FALSE, eval=FALSE}
fit.piecewise=lm(Starting.Median.Salary~AdmitRate+I((AdmitRate-.155)*(AdmitRate>.155))+I((AdmitRate-.6)*(AdmitRate>.6)), data=fDTNoOut)
summary(fit.piecewise)
```

```{r Piecewise No Transformation}
piecewise.noTransformation=lm(Starting.Median.Salary~ CostOState + EntranceDifficulty + 
                 CollegeType+Undergraduates + Applicants + Region+
                   AdmitRate+I((AdmitRate-.155)*(AdmitRate>.155))+I((AdmitRate-.6)*(AdmitRate>.6)), data=fDTNoOut[train,])
pw.noTransformation.mse.test <- mean((fDTNoOut$Starting.Median.Salary-predict(piecewise.noTransformation,fDTNoOut))[-train]^2)
```

```{r Piecewise Logged}
piecewise.logged=lm(log(Starting.Median.Salary)~ CostOState + EntranceDifficulty + 
                 CollegeType+Undergraduates + Applicants + Region+
                   AdmitRate+I((AdmitRate-.155)*(AdmitRate>.155))+I((AdmitRate-.6)*(AdmitRate>.6)), data=fDTNoOut[train,])
pw.logged.mse.test <- mean((fDTNoOut$Starting.Median.Salary-exp(predict(piecewise.logged,fDTNoOut)))[-train]^2)
```

```{r Piecewise Interaction}
piecewise.interaction=lm(Starting.Median.Salary~ CostOState + EntranceDifficulty + 
                 CollegeType*Undergraduates + Applicants + Region+
                   AdmitRate+I((AdmitRate-.155)*(AdmitRate>.155))+I((AdmitRate-.6)*(AdmitRate>.6)), data=fDTNoOut[train,])
pw.interaction.mse.test <- mean((fDTNoOut$Starting.Median.Salary-predict(piecewise.interaction,fDTNoOut))[-train]^2)
```

```{r MSE}
mse.table<- matrix(c(ols.noTransformation.mse.test, ols.logged.mse.test, ols.interaction.mse.test,
                     wls.noTransformation.mse.test, wls.logged.mse.test, wls.interaction.mse.test, 
                     pw.noTransformation.mse.test, pw.logged.mse.test, pw.interaction.mse.test),
                   ncol=3, byrow=TRUE)
colnames(mse.table) <- c("No Transformations","Logged", "Interaction")
rownames(mse.table) <- c("OLS","WLS","Piecewise")
mse.table <- as.table(mse.table)
mse.table
```

```{r Prediction}
summary(lm.fit.wls1)
```

##Section 6 Analysis of Results	 (20 pts.) 

Analysis and presentation of results. Your analysis and results need to contain some narrative to allow your audience to understand what you did. A simple output and diagram dump with no explanation will receive very little credit. Every procedure, output and diagram needs to be briefly but appropriately introduced before and briefly commented on its meaning after. Don’t leave it up to the reader to interpret what you did. 


##Section 7 Conclusion	(15 pts.) 

A short section with final thoughts, conclusions and lessons learned. These conclusions must contain a discussion of: 

a.	Your final model method and specification selection. Why did you pick this particular modeling method and model specification. 

We select the WLS with no transformations as our model because it has the lowest MSE comparitively to all the other modeling methods and specification combinations while still maintaining our key goal of interpretibility.

b.	The main conclusions of your analysis. These conclusions must answer/solve your analytics question/problem stated in 1 above. Please be brief but concise and discuss the main insights you obtained from your analysis 

We learned that many varibales contribute in determining what the median starting salary is for college graduates. However, our most iluminating find was how much the reputation and branding of a school has on starting median salaries. Our outliers contained 5/7 Ivys and other prestigious schools like MIT and Staford. It appears that these highly prestegious and recognizable schools impact salaries more than the other variables included in our list. It would be interesting to find data and include a school's reputation if we continued on with this project.

c.	A brief statement of your lessons learned in this project in terms of: data issues, methodological challenges, do's and don'ts, what you learned from this experience. You don't need to address all of this. But please be thoughtful and make it interesting. 

Since we have an ad hoc dataset (we created it), we ran into issues of having a small number of data points with full data. We only have information for roughly 17% of the schools we collected. 
Understnading how to re-transform logged models to get an MSE than can be compared to our other two models was challenging.

