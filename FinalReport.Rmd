---
title: "Final Report"
author: "Group Name"
date: "May 3, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r Load Package and Datasets}
library(perturb)
library(tidyverse)
library(tree)
library(class)
library(car)
fullDataTraining <- read.csv("FullDataTrainingComplete.csv", header = TRUE, stringsAsFactors = FALSE)
```


The final project report will contain the following sections:

##Section 1 Analytics Question/Problem (5 pts.) 

The analytics question/problem being addressed. In your framing of the analytics question, please state clearly articulate: 

a.	The specific predictive analytic question you are attempting to answer, or problem you are trying to solve? Since this course is about predictive analytics, it is important that you clearly specify the response variable you are predicting. 

b.	What type of problem or question you are addressing – i.e., quantitative or classification 

c.	What your analytics goal(s) is(are) – i.e., inference, interpretation and/or prediction. 


One of the main reasons students attend universities in the US is the hope of getting a better paying job once they graduated. Our hope is to figure out do certain universities provide a better opportunity of doing this than others. Our team wants to predict given a school and several school statistics, can we predict the starting median salary that a graduate from that particular university would earn.

Since our team wants to predict a starting salary this problem is a quantitative problem. Our main goal is to compare salaries that we do not know with salaries that we do know therefore the main analytical goal here is high predictive accuracy.


##Section 2 Business Rational (10 pts.)

A brief but compelling business rationale about the importance of this question/problem from a business perspective. Why is the problem you are analyzing important? 

This analytics question is important from two perspectives: a student and a school.

For the student:

For students entering a university a career is several years away, knowing what the salary is for alumni may influence their decision as where to go. On top of this with the known cost of the university and their predicted salary they would be able to determine a general return on investment as well how long their payback period would be.


For the school:

Even though admission rates throughout the country are decreasing, schools are still competing to attract top talent. While there are numerous reasons to attend schools (close to home, prestige of a university, or top program for a degree) one of the major reasons to attend is money. Going to a university is an investment and the cost of that investment is increasing. Therefore universities need to justify that investment to their customers, one of the best ways to do this is with their alumni starting salary. 


##Section 3 Description of the Data (10 pts.) 

A description of the data set utilized for the analysis (if the data set is not available in an R package or public web site, the data set must be attached). Your data description should be sufficient for your reading audience to understand your data set, variables and the interpretations you provide in your report, including variable types and units of measurement. The data description should be accompanied by any necessary descriptive analytics artifacts necessary for your predictive modeling (e.g., descriptive statistics, correlation matrix, correlation plots, other plots, etc.). 

The data for this project originated from two sources. The first is from a Kaggle Dataset called Where it Pays to Attend College. This data set includes the university, region, and the schools alumnus median starting salary (in \$) and mid-career salary at certain percentiles (in \$). The second was collected from publicly available information on www.collegedata.com, this data includes admission rates (as decimal), number of undergraduates, cost of tuition (in \$), and location of the school. These datasets were combined together and is attached to this report.

Need descriptive statistics correlation matrix and correlation plots other plots



##Section 4 Pre-Processing	 (10 pts.) 

A discussion of any pre-processing (e.g., grouping, combining variables, etc.) and transformations done with the data (e.g., normality, logs, standardization, non-linear, etc.), along with the rationale for the appropriateness of this transformation. 

##Section 5 Model Justification (20 pts.) 

A justification for the analytics methods and model specifications used. All methods used must be appropriate and relevant to the problem and you need to provide a justification for the selected methods based on: 

a.	Conformance with or departure from OLS assumptions; If you are using OLS as one of your methods, you must test key OLS assumptions. If you don’t plan to use the OLS model, you need to specify which OLS assumption would be violated. 

b.	Analysis goals (i.e., inference, interpretation and/or accuracy); you must specify your analysis goal(s). 

c.	Predictive accuracy based on cross-validation test statistics. Similarly, the particular model specifications utilized must have a rationale. For example, if you chose a quadratic regression specification, you must have some rationale for the respective non-linear relationship. All projects must be analyzed with a variety of appropriate model with different model specification. Please consult with me if in doubt, but these are the minimum requirements 

All projects must evaluate 3 different methods, with 2 different model specifications for each. You need to provide in this section a sound justification for your choice of models to evaluate. 


log.model <- lm(log(Starting.Median.Salary) ~ CostIState + CostOState + CollegeType + Undergraduates + 
EntranceDifficulty + AdmitRate + Applicants + City +State + Region, data=fullDataTraining[train,])



```{r}
# log.model.1.null <- lm(log(Starting.Median.Salary) ~ log(CostIState), data=fullDataTraining)
# log.model.1.full <- lm(log(Starting.Median.Salary) ~ . -CostOState -CostIState +log(CostIState)-
#                          Mid.Career.25th.Percentile.Salary - Mid.Career.Median.Salary - 
#                          Mid.Career.10th.Percentile.Salary - Mid.Career.75th.Percentile.Salary -
#                          Mid.Career.90th.Percentile.Salary, data=fullDataTraining)
# 
# log.model.1.forward <- step(log.model.1.null, scope=list(lower=log.model.1.null, upper=log.model.1.full), direction="forward", test="F")
```


```{r training split}
train <- sample(1:nrow(fullDataTraining), 0.8*nrow(fullDataTraining))

```


```{r full logistic regression}
#Specification 1
log.model.1.full <- lm(log(Starting.Median.Salary) ~ log(CostIState) + Undergraduates + 
EntranceDifficulty + AdmitRate + Applicants + Region, data=fullDataTraining)
summary(log.model.1.full)

#vif(log.model.1.full)

train.fit.1 <- lm(log(Starting.Median.Salary) ~ log(CostIState) + Undergraduates + 
EntranceDifficulty + AdmitRate + Applicants + Region, data=fullDataTraining[train,])
summary(train.fit.1)

#predict(train.fit.1, fullDataTraining)[-train]

mse.test.1 <- mean((log(fullDataTraining$Starting.Median.Salary)-predict(train.fit.1, fullDataTraining))[-train]^2)
mse.test.1 # Check it out

#Specification 2

log.model.2.full <- lm(log(Starting.Median.Salary) ~ log(CostOState) + CollegeType + Undergraduates + 
EntranceDifficulty + AdmitRate + Applicants + Region, data=fullDataTraining)
summary(log.model.2.full)

#vif(log.model.2.full)

train.fit.2 <- lm(log(Starting.Median.Salary) ~ log(CostOState) + CollegeType + Undergraduates + 
EntranceDifficulty + AdmitRate + Applicants + Region, data=fullDataTraining[train,])
summary(train.fit.2)

#predict(train.fit.2, fullDataTraining)[-train]

mse.test.2 <- mean((log(fullDataTraining$Starting.Median.Salary)-predict(train.fit.2, fullDataTraining))[-train]^2)
mse.test.2 # Check it out


#Specificaiton 3
log.model.3.full <- lm(log(Starting.Median.Salary) ~ log(CostOState) + log(CostIState)+  Undergraduates + 
EntranceDifficulty + AdmitRate + Applicants + Region, data=fullDataTraining)
summary(log.model.3.full)

#vif(log.model.3.full)

train.fit.3 <- lm(log(Starting.Median.Salary) ~ log(CostOState) + log(CostIState)+  Undergraduates + 
EntranceDifficulty + AdmitRate + Applicants + Region, data=fullDataTraining[train,])
summary(train.fit.3)

#predict(train.fit.3, fullDataTraining)[-train]

mse.test.3 <- mean((log(fullDataTraining$Starting.Median.Salary)-predict(train.fit.3, fullDataTraining))[-train]^2)
mse.test.3 # Check it out

cbind("Model 1 MSE"=mse.test.1, "Model 2 MSE"=mse.test.2, "Model 3 MSE" = mse.test.3)

```

```{r CART}

tree.fullDataTrain=tree(Starting.Median.Salary ~ log(CostIState) + Undergraduates + 
EntranceDifficulty + AdmitRate + Applicants + Region, data=fullDataTraining,subset=train)

yhat=predict(tree.fullDataTrain,newdata=fullDataTraining[-train,]) 
fullDataTrain.test= fullDataTraining[-train,"Starting.Median.Salary"] # These are the actual values
plot(yhat,fullDataTrain.test) # Let's plot predicted vs. actual
abline(0,1) # And draw a line
mean((yhat-fullDataTrain.test)^2) # And calculate the MSE



```

```{r KNN}

```

```{r Best Selection}

```

```{r Prediction}

```







##Section 6 Analysis of Results	 (20 pts.) 

Analysis and presentation of results. Your analysis and results need to contain some narrative to allow your audience to understand what you did. A simple output and diagram dump with no explanation will receive very little credit. Every procedure, output and diagram needs to be briefly but appropriately introduced before and briefly commented on its meaning after. Don’t leave it up to the reader to interpret what you did. 

##Section 7 Conclusion	(15 pts.) 

A short section with final thoughts, conclusions and lessons learned. These conclusions must contain a discussion of: 

a.	Your final model method and specification selection. Why did you pick this particular modeling method and model specification. 

b.	The main conclusions of your analysis. These conclusions must answer/solve your analytics question/problem stated in 1 above. Please be brief but concise and discuss the main insights you obtained from your analysis 

c.	A brief statement of your lessons learned in this project in terms of: data issues, methodological challenges, do's and don'ts, what you learned from this experience. You don't need to address all of this. But please be thoughtful and make it interesting. 

